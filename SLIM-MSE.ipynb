{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import fmin\n",
    "import scipy.sparse as sps\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "# Numpy cries because it is an old code so we monkey patch it\n",
    "np.int = int\n",
    "np.bool = bool\n",
    "np.float = float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_all_dataframe = pd.read_csv('data_train.csv', \n",
    "                                sep=\",\", \n",
    "                                header= 0, \n",
    "                                dtype={0:int, 1:int, 2:float},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"UserID\", \"ItemID\", \"Interaction\"]\n",
    "\n",
    "\n",
    "# Build the COO sparse matrix associated with the URM\n",
    "URM_all = sps.coo_matrix((URM_all_dataframe[\"Interaction\"].values, \n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values))) ## .values --> numpy array, df[..] --> pd series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 593 (4.55 %) of 13025 users have no train items\n",
      "Warning: 2597 (19.94 %) of 13025 users have no sampled items\n",
      "Warning: 841 (6.46 %) of 13025 users have no train items\n",
      "Warning: 2993 (22.98 %) of 13025 users have no sampled items\n",
      "EvaluatorHoldout: Ignoring 2993 (23.0%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 2597 (19.9%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "URM_train, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.8)\n",
    "URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train, train_percentage = 0.80)\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SLIMElasticNetRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 841 ( 6.5%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 422 ( 1.9%) items with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 593 ( 4.6%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 241 ( 1.1%) items with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 387 ( 3.0%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 126 ( 0.6%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "recommender1 = SLIMElasticNetRecommender(URM_train , verbose = True)\n",
    "recommender2 = SLIMElasticNetRecommender(URM_train + URM_validation , verbose = True)\n",
    "recommender3 = SLIMElasticNetRecommender(URM_train + URM_validation + URM_test , verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 7202 (32.2%) in 5.00 min. Items per second: 24.00\n",
      "SLIMElasticNetRecommender: Processed 14815 (66.3%) in 10.00 min. Items per second: 24.69\n",
      "SLIMElasticNetRecommender: Processed 21778 (97.4%) in 15.00 min. Items per second: 24.20\n",
      "SLIMElasticNetRecommender: Processed 22348 (100.0%) in 15.46 min. Items per second: 24.09\n"
     ]
    }
   ],
   "source": [
    "recommender2.fit(topK = 1000, l1_ratio = 0.00012799243915346593, alpha = 0.003418632950338217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SLIMElasticNetRecommender' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tommaso\\Desktop\\RecSysCompetition\\RecSys-Competition\\SLIM-MSE.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Tommaso/Desktop/RecSysCompetition/RecSys-Competition/SLIM-MSE.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m recommender2\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mTommaso\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDesktop\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mRecSysCompetition\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mRecSys-Competition\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mgianni\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SLIMElasticNetRecommender' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "recommender2.save('C:\\\\Users\\\\Tommaso\\\\Desktop\\\\RecSysCompetition\\\\RecSys-Competition\\\\gianni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of stdout:\n",
      "_cython_magic_7dfaf4401a5ee9adcf9cfcc073561b3c96f72579.c\n",
      "   Creazione della libreria C:\\Users\\Tommaso\\.ipython\\cython\\Users\\Tommaso\\.ipython\\cython\\_cython_magic_7dfaf4401a5ee9adcf9cfcc073561b3c96f72579.cp311-win_amd64.lib e dell'oggetto C:\\Users\\Tommaso\\.ipython\\cython\\Users\\Tommaso\\.ipython\\cython\\_cython_magic_7dfaf4401a5ee9adcf9cfcc073561b3c96f72579.cp311-win_amd64.exp\n",
      "Generazione codice in corso...\n",
      "Generazione codice terminata"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.sparse as sps\n",
    "\n",
    "from libc.stdlib cimport rand, srand, RAND_MAX\n",
    "\n",
    "def train_multiple_epochs(URM_train, learning_rate_input, regularization_2_input, n_epochs,evaluator_validation, recommender_object,SM):\n",
    "\n",
    "    URM_train_coo = URM_train.tocoo()\n",
    "    cdef int n_items = URM_train.shape[1]\n",
    "    cdef int n_interactions = URM_train.nnz\n",
    "    cdef int[:] URM_train_coo_row = URM_train_coo.row\n",
    "    cdef int[:] URM_train_coo_col = URM_train_coo.col\n",
    "    cdef double[:] URM_train_coo_data = URM_train_coo.data\n",
    "    cdef int[:] URM_train_indices = URM_train.indices\n",
    "    cdef int[:] URM_train_indptr = URM_train.indptr\n",
    "    cdef double[:] URM_train_data = URM_train.data\n",
    "\n",
    "    cdef double[:,:] item_item_S = SM\n",
    "    cdef double learning_rate = learning_rate_input\n",
    "    cdef double regularization_2 = regularization_2_input\n",
    "    cdef double loss = 0.0\n",
    "    cdef long start_time\n",
    "    cdef double true_rating, predicted_rating, prediction_error, profile_rating\n",
    "    cdef int start_profile, end_profile\n",
    "    cdef int index, sample_num, user_id, item_id, profile_item_id\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "        \n",
    "        loss = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for sample_num in range(n_interactions):\n",
    "\n",
    "            # Randomly pick sample\n",
    "            index = rand() % n_interactions\n",
    "\n",
    "            user_id = URM_train_coo_row[index]\n",
    "            item_id = URM_train_coo_col[index]\n",
    "            true_rating = URM_train_coo_data[index]\n",
    "\n",
    "            # Compute prediction\n",
    "            start_profile = URM_train_indptr[user_id]\n",
    "            end_profile = URM_train_indptr[user_id+1]\n",
    "            predicted_rating = 0.0\n",
    "\n",
    "            for index in range(start_profile, end_profile):\n",
    "                profile_item_id = URM_train_indices[index]\n",
    "                profile_rating = URM_train_data[index]\n",
    "                predicted_rating += item_item_S[profile_item_id,item_id] * profile_rating\n",
    "\n",
    "            # Compute prediction error, or gradient\n",
    "            prediction_error = true_rating - predicted_rating\n",
    "            loss += prediction_error**2\n",
    "\n",
    "            # Update model, in this case the similarity\n",
    "            for index in range(start_profile, end_profile):\n",
    "                profile_item_id = URM_train_indices[index]\n",
    "                profile_rating = URM_train_data[index]\n",
    "                item_item_S[profile_item_id,item_id] += learning_rate * (prediction_error * profile_rating - \n",
    "                                                                         regularization_2 * item_item_S[profile_item_id,item_id])\n",
    "\n",
    "            # Ensure diagonal is always zero\n",
    "            item_item_S[item_id,item_id] = 0.0\n",
    "        \n",
    "#             if sample_num % 1000000 == 0:\n",
    "#                 print(\"Epoch {}: {:.2f}%\".format(n_epoch+1, sample_num/n_interactions*100))\n",
    "            \n",
    "        #result_df, _ = evaluator_validation.evaluateRecommender(recommender_object)\n",
    "        #val_MAP = result_df.loc[10][\"MAP\"]\n",
    "        elapsed_time = time.time() - start_time\n",
    "        samples_per_second = (sample_num+1)/elapsed_time\n",
    "\n",
    "        if(n_epoch < 1000 ):\n",
    "            print(\"Epoch {} complete in in {:.2f} seconds, loss is {:.3E}. Samples per second {:.2f}.\".format(n_epoch+1, time.time() - start_time, loss/(sample_num+1), samples_per_second))\n",
    "        else:\n",
    "            sparse_similarity = sps.csr_matrix(item_item_S)\n",
    "            recommender_object.set_similarity_matrix(sparse_similarity)\n",
    "            result_df, _ = evaluator_validation.evaluateRecommender(recommender_object)\n",
    "            val_MAP = result_df.loc[10][\"MAP\"]\n",
    "            print(\"Epoch {} complete in in {:.2f} seconds, loss is {:.3E}. Samples per second {:.2f}. Validation MAP {:.4f}\".format(n_epoch+1, time.time() - start_time, loss/(sample_num+1), samples_per_second,val_MAP))\n",
    "\n",
    "    return np.array(item_item_S), loss/(sample_num+1), val_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizations_array = np.logspace(-2.5, 1, num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_list = []\n",
    "loss_list = []\n",
    "val_map_list = []\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(regularizations_array)):\n",
    "    # Initializing the similarity matrix\n",
    "    n_items = URM_train.shape[1]\n",
    "    item_item_S = np.zeros((n_items, n_items), dtype = float)\n",
    "    item_item_S, loss, map = train_multiple_epochs(URM_train, learning_rate, regularizations_array[i],1001, evaluator_validation, recommender,item_item_S)\n",
    "    sim_matrix_list.append(item_item_S)\n",
    "    loss_list.append(loss)\n",
    "    val_map_list.append(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Similarity matrix in a recommender_object instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010403661497753383,\n",
       " 0.010081089892359028,\n",
       " 0.008689386834901055,\n",
       " 0.007378339506348257,\n",
       " 0.008551618877111238]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_map_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_S = np.load('W_sparse.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = item_item_S['indices']\n",
    "indptr = item_item_S['indptr']\n",
    "format = item_item_S['format']\n",
    "shape = item_item_S['shape']\n",
    "data = item_item_S['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_similarity = csr_matrix((data, indices, indptr), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommender1.set_similarity_matrix(sparse_similarity)\n",
    "# recommender2.set_similarity_matrix(sparse_similarity)\n",
    "recommender3.set_similarity_matrix(sparse_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313, 99, 764, 636, 63]\n"
     ]
    }
   ],
   "source": [
    "print( recommender3.recommend(100)[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10428 (100.0%) in 9.89 sec. Users per second: 1055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PRECISION                          0.0\n",
       "PRECISION_RECALL_MIN_DEN           0.0\n",
       "RECALL                             0.0\n",
       "MAP                                0.0\n",
       "MAP_MIN_DEN                        0.0\n",
       "MRR                                0.0\n",
       "NDCG                               0.0\n",
       "F1                                 0.0\n",
       "HIT_RATE                           0.0\n",
       "ARHR_ALL_HITS                      0.0\n",
       "NOVELTY                       0.004796\n",
       "AVERAGE_POPULARITY            0.279899\n",
       "DIVERSITY_MEAN_INTER_LIST     0.957545\n",
       "DIVERSITY_HERFINDAHL          0.995745\n",
       "COVERAGE_ITEM                 0.217827\n",
       "COVERAGE_ITEM_HIT                  0.0\n",
       "ITEMS_IN_GT                   0.797297\n",
       "COVERAGE_USER                 0.800614\n",
       "COVERAGE_USER_HIT                  0.0\n",
       "USERS_IN_GT                   0.800614\n",
       "DIVERSITY_GINI                0.036422\n",
       "SHANNON_ENTROPY               9.563713\n",
       "RATIO_DIVERSITY_HERFINDAHL    0.996105\n",
       "RATIO_DIVERSITY_GINI          0.103978\n",
       "RATIO_SHANNON_ENTROPY         0.736204\n",
       "RATIO_AVERAGE_POPULARITY      2.285329\n",
       "RATIO_NOVELTY                 0.224457\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df, _ = evaluator_test.evaluateRecommender(recommender3)\n",
    "result_df.loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>PRECISION_RECALL_MIN_DEN</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAP_MIN_DEN</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>F1</th>\n",
       "      <th>HIT_RATE</th>\n",
       "      <th>ARHR_ALL_HITS</th>\n",
       "      <th>...</th>\n",
       "      <th>COVERAGE_USER</th>\n",
       "      <th>COVERAGE_USER_HIT</th>\n",
       "      <th>USERS_IN_GT</th>\n",
       "      <th>DIVERSITY_GINI</th>\n",
       "      <th>SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_DIVERSITY_HERFINDAHL</th>\n",
       "      <th>RATIO_DIVERSITY_GINI</th>\n",
       "      <th>RATIO_SHANNON_ENTROPY</th>\n",
       "      <th>RATIO_AVERAGE_POPULARITY</th>\n",
       "      <th>RATIO_NOVELTY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutoff</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775048</td>\n",
       "      <td>0.035656</td>\n",
       "      <td>9.5354</td>\n",
       "      <td>0.996052</td>\n",
       "      <td>0.10179</td>\n",
       "      <td>0.734024</td>\n",
       "      <td>2.296514</td>\n",
       "      <td>0.224177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECISION PRECISION_RECALL_MIN_DEN RECALL  MAP MAP_MIN_DEN  MRR NDCG  \\\n",
       "cutoff                                                                        \n",
       "10           0.0                      0.0    0.0  0.0         0.0  0.0  0.0   \n",
       "\n",
       "         F1 HIT_RATE ARHR_ALL_HITS  ... COVERAGE_USER COVERAGE_USER_HIT  \\\n",
       "cutoff                              ...                                   \n",
       "10      0.0      0.0           0.0  ...      0.775048               0.0   \n",
       "\n",
       "       USERS_IN_GT DIVERSITY_GINI SHANNON_ENTROPY RATIO_DIVERSITY_HERFINDAHL  \\\n",
       "cutoff                                                                         \n",
       "10        0.775048       0.035656          9.5354                   0.996052   \n",
       "\n",
       "       RATIO_DIVERSITY_GINI RATIO_SHANNON_ENTROPY RATIO_AVERAGE_POPULARITY  \\\n",
       "cutoff                                                                       \n",
       "10                  0.10179              0.734024                 2.296514   \n",
       "\n",
       "       RATIO_NOVELTY  \n",
       "cutoff                \n",
       "10          0.224177  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recommender.recommend(41)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the predictions on submission.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id                                          item_list\n",
      "0        1              36 101 506 592 694 403 123 1422 25 52\n",
      "1        2                     1095 12 50 26 3 47 11 54 4 196\n",
      "2        3                 59 259 2 9 956 375 536 130 648 970\n",
      "3        4                      28 249 50 5 1 146 6 314 2 128\n",
      "4        5                     77 1570 4 170 2 95 8 20 471 19\n",
      "5        6                       886 395 9 184 2 35 6 7 19 15\n",
      "6        8               210 443 451 722 80 95 600 760 4 1996\n",
      "7        9  3504 859 3646 12741 341 316 2028 10729 13302 2204\n",
      "8       10         1446 1816 2423 561 1668 2617 7 3 1767 2565\n",
      "9       11                   58 40 31 955 99 185 34 93 67 188\n"
     ]
    }
   ],
   "source": [
    "def write_predictions(recommender_object, at=10):\n",
    "    prediction_df = pd.read_csv('data_target_users_test.csv', sep= \",\",\n",
    "                                header=0, \n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "    #prediction_df['mapped user'] = prediction_df['user_id'].map(user_original_ID_to_index).fillna(-1).astype(int)\n",
    "    #prediction_df['item_list'] = prediction_df['mapped user'].apply(recommender_object.recommend)\n",
    "    prediction_df['item_list'] = prediction_df['user_id'].apply(lambda user_id: recommender_object.recommend(user_id)[:at])\n",
    "    #def map_items(item_list):\n",
    "    #    return [index_to_item_original.get(item, item) for item in item_list]\n",
    "\n",
    "    #prediction_df['item_list'] = prediction_df['item_list'].apply(map_items)\n",
    "    def transform_items_to_string(item_list):\n",
    "        return ' '.join(map(str, item_list))\n",
    "\n",
    "    prediction_df['item_list'] = prediction_df['item_list'].apply(transform_items_to_string)\n",
    "    print(prediction_df.head(10))\n",
    "    #del prediction_df['mapped user']\n",
    "    prediction_df.to_csv('submission.csv',index=False)\n",
    "\n",
    "write_predictions(recommender3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.read_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
