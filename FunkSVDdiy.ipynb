{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_all_dataframe = pd.read_csv('data_train.csv', \n",
    "                                sep=\",\", \n",
    "                                header= 0, \n",
    "                                dtype={0:int, 1:int, 2:float},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"UserID\", \"ItemID\", \"Interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserID  ItemID  Interaction\n",
       "0        1       7          1.0\n",
       "1        1      15          1.0\n",
       "2        1      16          1.0\n",
       "3        1     133          1.0\n",
       "4        1     161          1.0\n",
       "..     ...     ...          ...\n",
       "95       4      47          1.0\n",
       "96       4      70          1.0\n",
       "97       4      79          1.0\n",
       "98       4     119          1.0\n",
       "99       4     125          1.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all_dataframe.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of interactions is 478730\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of interactions is {}\".format(len(URM_all_dataframe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of unique user id and item id \n",
    "userID_unique = URM_all_dataframe[\"UserID\"].unique()\n",
    "itemID_unique = URM_all_dataframe[\"ItemID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items\t 22222, Number of users\t 12638\n",
      "Max ID items\t 22347, Max Id users\t 13024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display some statistics\n",
    "n_users = len(userID_unique)\n",
    "n_items = len(itemID_unique)\n",
    "n_interactions = len(URM_all_dataframe)\n",
    "\n",
    "print (\"Number of items\\t {}, Number of users\\t {}\".format(n_items, n_users))\n",
    "print (\"Max ID items\\t {}, Max Id users\\t {}\\n\".format(max(itemID_unique), max(userID_unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13025x22348 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 478730 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move to sparse format\n",
    "import scipy.sparse as sps\n",
    "\n",
    "URM_train = sps.coo_matrix((URM_all_dataframe[\"Interaction\"].values, \n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values))) ## .values --> numpy array, df[..] --> pd series\n",
    "\n",
    "# Go to CSR format\n",
    "URM_train.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: Number of items\t 22348, Number of users\t 13025\n"
     ]
    }
   ],
   "source": [
    "N_USERS_TRAIN, N_ITEMS_TRAIN = URM_train.shape\n",
    "print (\"Training set: Number of items\\t {}, Number of users\\t {}\".format(N_ITEMS_TRAIN, N_USERS_TRAIN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe removing all the items with no interaction (or no very positive interaction, in our case) can be useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RecommenderObject for the FunkSVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of stdout:\n",
      "_cython_magic_89fcdd45de0bbcfa63b104f2e4dcad77b09592b9.c\n",
      "   Creating library C:\\Users\\melan\\.ipython\\cython\\Users\\melan\\.ipython\\cython\\_cython_magic_89fcdd45de0bbcfa63b104f2e4dcad77b09592b9.cp311-win_amd64.lib and object C:\\Users\\melan\\.ipython\\cython\\Users\\melan\\.ipython\\cython\\_cython_magic_89fcdd45de0bbcfa63b104f2e4dcad77b09592b9.cp311-win_amd64.exp\n",
      "Generating code\n",
      "Finished generating code"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from libc.stdlib cimport rand, srand, RAND_MAX\n",
    "\n",
    "class FunkSVDRecommender(object):\n",
    "    def __init__(self, n_epochs= 100, n_factors= 10, learning_rate= 1e-4, regularization_factor= 1e-5):\n",
    "        self.n_factors = n_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization_factor = regularization_factor\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "        self.user_factors = None\n",
    "        self.item_factors = None\n",
    "\n",
    "        self.model_name = \"FunkSVD\"\n",
    "\n",
    "    def fit(self, URM_train, n_factors= 10, l_rate= 1e-3, regularization_factor= 1e-5):\n",
    "        '''\n",
    "        Fit the FunkSVD model to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - URM_train: Sparse user-item interaction matrix (training data)\n",
    "        - n_factors: Number of latent factors\n",
    "        - l_rate: Learning rate for the optimization algorithm\n",
    "        - regularization_factor: Regularization factor to prevent overfitting\n",
    "        '''\n",
    "\n",
    "        # Initialize the model with the training data\n",
    "        self.URM_train = URM_train\n",
    "\n",
    "        # Convert the sparse URM_train matrix to a coordinate format for efficient access\n",
    "        URM_train_coo = URM_train.tocoo()\n",
    "\n",
    "        # Extract the number of users, items, and interactions from the URM_train matrix\n",
    "        self.n_users, self.n_items = URM_train_coo.shape\n",
    "        self.n_interactions = URM_train.nnz\n",
    "\n",
    "        # Declare variables using Cython for faster execution\n",
    "        cdef int n_interactions = URM_train.nnz\n",
    "        cdef int sample_num, sample_index, user_id, item_id, factor_index\n",
    "        cdef double rating, predicted_rating, prediction_error\n",
    "        cdef int num_factors = self.n_factors\n",
    "        cdef double lr = self.learning_rate\n",
    "        cdef double alpha = self.regularization_factor\n",
    "\n",
    "        # Extract data from the URM_train_coo matrix\n",
    "        cdef int[:] URM_train_coo_row = URM_train_coo.row\n",
    "        cdef int[:] URM_train_coo_col = URM_train_coo.col\n",
    "        cdef double[:] URM_train_coo_data = URM_train_coo.data\n",
    "\n",
    "        # Initialize user and item factors with random values\n",
    "        cdef double[:,:] user_factors = np.random.random((self.n_users, num_factors))\n",
    "        cdef double[:,:] item_factors = np.random.random((self.n_items, num_factors))\n",
    "        cdef double H_i, W_u\n",
    "        cdef double item_factors_update, user_factors_update\n",
    "        cdef double loss\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            loss = 0.0\n",
    "\n",
    "            for sample_num in range(n_interactions):\n",
    "                # Randomly choose an interaction index\n",
    "                sample_index = rand() % n_interactions\n",
    "                \n",
    "                # Extract user, item, and rating information for the chosen interaction\n",
    "                user_id = URM_train_coo_row[sample_index]\n",
    "                item_id = URM_train_coo_col[sample_index]\n",
    "                rating = URM_train_coo_data[sample_index]\n",
    "\n",
    "                predicted_rating = 0.0\n",
    "                \n",
    "                # Calculate the predicted rating using user and item factors\n",
    "                for factor_index in range(num_factors):\n",
    "                    predicted_rating += user_factors[user_id, factor_index] * item_factors[item_id, factor_index]\n",
    "\n",
    "                # Calculate prediction error and update the loss\n",
    "                prediction_error = rating - predicted_rating\n",
    "                loss += prediction_error**2\n",
    "\n",
    "                # Update user and item factors based on the prediction error and regularization\n",
    "                for factor_index in range(num_factors):\n",
    "                    \n",
    "                    H_i = item_factors[item_id, factor_index]\n",
    "                    W_u = user_factors[user_id, factor_index]  \n",
    "\n",
    "                    user_factors_update = prediction_error * H_i - alpha * W_u\n",
    "                    item_factors_update = prediction_error * W_u - alpha * H_i\n",
    "\n",
    "                    user_factors[user_id, factor_index] += lr * user_factors_update \n",
    "                    item_factors[item_id, factor_index] += lr * item_factors_update    \n",
    "\n",
    "        # Save train loss\n",
    "        self.train_loss = loss\n",
    "\n",
    "        # Save factorization\n",
    "        self.user_factors = user_factors\n",
    "        self.item_factors = item_factors\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        '''\n",
    "        Predict the rating for a single user-item pair based on the learned factors.\n",
    "        '''\n",
    "        # Predict the rating for a user-item pair based on the learned factors\n",
    "        cdef double[:] user_vector = self.user_factors[user_id, :]\n",
    "        cdef double[:] item_vector = self.item_factors[item_id, :]\n",
    "        cdef double predicted_rating = np.dot(user_vector, item_vector)\n",
    "\n",
    "        return predicted_rating\n",
    "        \n",
    "    \n",
    "    def recommend(self, user_id, at=10, remove_seen=True):\n",
    "        '''\n",
    "        Predict the ratings for all the items available for a single user.\n",
    "        '''\n",
    "        cdef int[:] item_ids = np.arange(self.n_items, dtype=np.int32)\n",
    "        cdef int[:] seen_items = np.empty(self.n_items, dtype=np.int32)\n",
    "        cdef int[:] recommended_indices\n",
    "\n",
    "        # Initialize list to store recommended items\n",
    "        recommended_items = []\n",
    "\n",
    "        # Predict ratings for all items\n",
    "        predicted_ratings = [np.float32(self.predict(user_id, item_id)) for item_id in item_ids]\n",
    "\n",
    "        if remove_seen:\n",
    "            # Get the items already seen by the user\n",
    "            try:\n",
    "                row_user_id = self.URM_train.getrow(user_id)\n",
    "                seen_items = row_user_id.nonzero()[1]\n",
    "                for seen_item in seen_items:\n",
    "                    predicted_ratings[seen_item] = -np.inf\n",
    "\n",
    "            except IndexError:\n",
    "                # If the row does not exist, do nothing or handle the case accordingly\n",
    "                pass\n",
    "\n",
    "        recommended_indices = np.argsort(predicted_ratings)[-at:][::-1].astype(np.int32)\n",
    "        recommended_items.extend(item_ids[i] for i in recommended_indices)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        samples_per_second = sample_num/elapsed_time\n",
    "        print(\"Epoch {} complete in in {:.2f} seconds, loss is {:.3E}. Samples per second {:.2f}\".format(n_epoch+1, time.time() - start_time, loss/sample_num, samples_per_second))\n",
    "\n",
    "        return np.array(recommended_items)\n",
    "\n",
    "    def write_predictions(self, at=10):\n",
    "        prediction_df = pd.read_csv('data_target_users_test.csv', sep= \",\",\n",
    "                                    header=0, \n",
    "                                    dtype={0:int},\n",
    "                                    engine='python')\n",
    "        #prediction_df=prediction_df[:10]\n",
    "\n",
    "        cdef int[:] user_array = np.array(prediction_df['user_id'])\n",
    "        cdef int[:,:] rec_array\n",
    "\n",
    "        rec_array = np.asarray([self.recommend(user_id, at=at) for user_id in np.asarray(user_array)]).reshape(len(user_array), at)\n",
    "        \n",
    "        print(\"Predictions done.\")\n",
    "        def transform_items_to_string(item_list):\n",
    "            return ' '.join(map(str, item_list))\n",
    "\n",
    "        prediction_df['item_list'] = np.asarray([transform_items_to_string(item) for item in rec_array])\n",
    "        print(\"Predictions successfully converted to string.\")\n",
    "        print(prediction_df.head(10))\n",
    "\n",
    "        prediction_df.to_csv('submission.csv',index=False)\n",
    "        print(\"Predictions successfully written to csv.\")\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the FunkSVD on our dataset and create recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunkSVD  model has reached a  321.13163825963665  loss on the train set.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "recommender = FunkSVDRecommender(n_epochs= 1000, n_factors= 20)\n",
    "\n",
    "# Fit the model for our dataset\n",
    "recommender.fit(URM_train)\n",
    "\n",
    "print(recommender.model_name, \" model has reached a \", recommender.train_loss, \" loss on the train set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>13010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>13012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10874</th>\n",
       "      <td>13013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10875</th>\n",
       "      <td>13015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10876</th>\n",
       "      <td>13019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>13020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>13021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>13022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>13023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>13024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id\n",
       "10872    13010\n",
       "10873    13012\n",
       "10874    13013\n",
       "10875    13015\n",
       "10876    13019\n",
       "10877    13020\n",
       "10878    13021\n",
       "10879    13022\n",
       "10880    13023\n",
       "10881    13024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import users ids for prediction\n",
    "prediction_df = pd.read_csv('data_target_users_test.csv', sep= \",\",\n",
    "                                header=0, \n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "prediction_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10175, 10620, 21205, 15653, 21965, 10832, 16263,  3861,  7900,\n",
       "       12153])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.recommend(13024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions done.\n",
      "Predictions successfully converted to string.\n",
      "   user_id                                          item_list\n",
      "0        1  13353 11233 6573 14929 10463 1811 11621 14566 ...\n",
      "1        2  725 12729 7935 18265 8132 4110 21101 14436 495...\n",
      "2        3  5162 21965 7662 15639 11133 20940 15064 13553 ...\n",
      "3        4  1295 6521 1186 4819 17657 6225 22289 15092 193...\n",
      "4        5  11038 17834 9377 14545 19916 4196 15793 22030 ...\n",
      "5        6  12149 22103 17325 14863 15434 12630 15462 1297...\n",
      "6        8  12063 12649 12460 13510 17379 5929 2466 13134 ...\n",
      "7        9  10175 21540 10620 8092 20118 11845 4492 14176 ...\n",
      "8       10  8167 21614 11994 18945 9816 16453 7649 18822 6...\n",
      "9       11  18265 9065 22336 21971 6225 9580 3400 13456 37...\n",
      "Predictions successfully written to csv.\n"
     ]
    }
   ],
   "source": [
    "recommender.write_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
